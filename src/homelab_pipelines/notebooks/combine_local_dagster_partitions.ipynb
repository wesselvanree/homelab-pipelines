{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad223285",
   "metadata": {},
   "source": [
    "# Combine local dagster partitions\n",
    "\n",
    "For experiment purposes, we can use dagster to fetch data locally. However, this may sometimes fail for large datasets. This notebook aims to collect the scraps to form a complete dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b903b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from homelab_pipelines.utils.paths import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540deb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bybit_symbols = pl.read_csv(\n",
    "    Paths.defs_data / \"bybit_symbols.csv\",\n",
    "    schema_overrides={\"launch_time\": pl.Datetime(\"ns\", \"UTC\")},\n",
    ")\n",
    "bybit_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effa9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_for_symbol(symbol: str) -> pl.DataFrame:\n",
    "    weekly_dir = Paths.repo_root / \"output\" / \"raw_bybit_prices_15min_weekly\"\n",
    "    recent_dir = Paths.repo_root / \"output\" / \"raw_bybit_prices_15min_recent\"\n",
    "\n",
    "    result = pl.concat(\n",
    "        [\n",
    "            pl.read_parquet(weekly_dir / symbol / p)\n",
    "            for p in glob(\n",
    "                \"*.parquet\",\n",
    "                root_dir=weekly_dir / symbol,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Loaded weekly partitions into dataframe of shape {result.shape}\")\n",
    "\n",
    "    try:\n",
    "        recent_data = pl.read_parquet(recent_dir / f\"{symbol}.parquet\").filter(\n",
    "            pl.col(\"start_time_utc\") > result.get_column(\"start_time_utc\").max()\n",
    "        )\n",
    "        print(f\"Adding {len(recent_data)} rows of recent data\")\n",
    "        result = pl.concat([result, recent_data])\n",
    "    except FileNotFoundError as err:\n",
    "        print(\"Could not find recent data\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def dataset_has_gaps(df: pl.DataFrame) -> bool:\n",
    "    temp = df.get_column(\"start_time_utc\").sort().diff(1, null_behavior=\"drop\").unique()\n",
    "    return len(temp) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27783470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in bybit_symbols.iter_rows(named=True):\n",
    "    symbol = row[\"symbol\"]\n",
    "    print()\n",
    "    print(f\"Processing {symbol}...\")\n",
    "    result = get_dataset_for_symbol(symbol)\n",
    "\n",
    "    if dataset_has_gaps(result):\n",
    "        print(\"Dataset has gaps, skipping this symbol\")\n",
    "        continue\n",
    "\n",
    "    result.write_parquet(Paths.repo_root / \"data\" / f\"{symbol}.parquet\")\n",
    "    print(f\"Written dataset of shape {result.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
