{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63870ab5",
   "metadata": {},
   "source": [
    "# Hidden markov model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from homelab_pipelines.utils.paths import Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    rv_rolling_rows: int = 8\n",
    "    \"\"\"Number of rows to consider for $RV_t$.\"\"\"\n",
    "    volsurp_window_days: int = 30\n",
    "    \"\"\"Number of days to consider for time-of-day mean of $VolSurp_t$.\"\"\"\n",
    "\n",
    "\n",
    "class HMMConfig:\n",
    "    n_days_train: int = 26 * 7  # 6 months\n",
    "\n",
    "\n",
    "class XGBoostConfig:\n",
    "    n_days_train: int = 2 * 52 * 7  # Two years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7cfd3",
   "metadata": {},
   "source": [
    "## Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ca536",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pl.read_parquet(Paths.repo_root / \"data\" / \"BTCUSDT.parquet\")\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08333fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58f9143",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "For the HMM, we generate certain features:\n",
    "\n",
    "- $RV_t$: realized volatility of the last $m$ bars\n",
    "- $|r_t|$ where $r_t$ is the Intraday log-return. This means assets that are not open 24 hours a day should omit the first observation of each day. Crypto assets are open the entire day, making this part slightly easier.\n",
    "- $\\text{VolSurp}_t$: volume surprise relative to the time-of-day mean\n",
    "- $\\text{Range}_t$: intraday high-low range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_day_start_time_seconds = 0\n",
    "trading_day_duration_seconds = 24 * 60 * 60\n",
    "\n",
    "X = (\n",
    "    prices.sort(\"start_time_utc\")\n",
    "    .with_columns(\n",
    "        log_range=pl.col(\"high\").log() - pl.col(\"low\").log(),\n",
    "        sfm=(\n",
    "            pl.col(\"start_time_utc\") - pl.col(\"start_time_utc\").dt.truncate(\"1d\")\n",
    "        ).dt.total_seconds(),\n",
    "        # Log returns log(close_{t}) - log(close_{t-k})\n",
    "        log_returns=pl.col(\"close\").log().diff(1),\n",
    "        log_returns_1=pl.col(\"close\").log().diff(1),\n",
    "        log_returns_4=pl.col(\"close\").log().diff(4),\n",
    "        # Log returns ahead\n",
    "        # NOTE: we need to multiply with -1 such that we get log(close_{t+k}) - log(close_{t})\n",
    "        log_returns_ahead_4=-pl.col(\"close\").log().diff(-4),\n",
    "    )\n",
    "    .with_columns(\n",
    "        realized_volatility=pl.col(\"log_returns\")\n",
    "        .pow(2)\n",
    "        .rolling_sum(Config.rv_rolling_rows)\n",
    "        .sqrt(),\n",
    "        abs_log_returns=pl.col(\"log_returns\").abs(),\n",
    "        # NOTE: crypto markets are open 24/7. When using this for other assets, this may not be the case.\n",
    "        trading_day_frac=(\n",
    "            (pl.col(\"sfm\") - trading_day_start_time_seconds).clip(\n",
    "                0, trading_day_duration_seconds\n",
    "            )\n",
    "            / trading_day_duration_seconds\n",
    "        ),\n",
    "    )\n",
    "    .with_columns(\n",
    "        trading_day_sin=pl.col(\"trading_day_frac\").sin(),\n",
    "        trading_day_cos=pl.col(\"trading_day_frac\").cos(),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate rolling volatility at each time of day\n",
    "X = X.join(\n",
    "    X.with_columns(\n",
    "        time_of_day=pl.col(\"start_time_utc\").dt.time(),\n",
    "    )\n",
    "    .rolling(\n",
    "        index_column=\"start_time_utc\",\n",
    "        period=f\"{Config.volsurp_window_days}d\",\n",
    "        group_by=\"time_of_day\",\n",
    "    )\n",
    "    .agg(\n",
    "        volume_mean_time_of_day_rolling=pl.col(\"volume\")\n",
    "        .clip(\n",
    "            lower_bound=pl.col(\"volume\").quantile(0.05),\n",
    "            upper_bound=pl.col(\"volume\").quantile(0.95),\n",
    "        )\n",
    "        .mean()\n",
    "    )\n",
    "    .drop(\"time_of_day\"),\n",
    "    on=\"start_time_utc\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "# Since we based our rolling mean volatility based on the first k days, we omit the first k days\n",
    "X = X.filter(\n",
    "    pl.col(\"start_time_utc\")\n",
    "    >= pl.col(\"start_time_utc\").min() + dt.timedelta(days=Config.volsurp_window_days)\n",
    ")\n",
    "\n",
    "# Calculate VolSurp\n",
    "X = X.with_columns(\n",
    "    volsurp=pl.col(\"volume\").log() - pl.col(\"volume_mean_time_of_day_rolling\").log()\n",
    ")\n",
    "X = X.sort(\"start_time_utc\")\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacec8cc",
   "metadata": {},
   "source": [
    "## Defining the model\n",
    "\n",
    "The model consists of two stages. First, we use a hidden markov model to estimate regimes. For each row, this gives us state probabilities and the expected duration within the current state. This is used as input for the ML model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegimeSwitchingModel:\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        self.hmm = GaussianHMM(**kwargs)\n",
    "        self._fitted_columns: Optional[List[str]] = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame) -> None:\n",
    "        self._fitted_columns = X.columns.to_list()\n",
    "        self.hmm.fit(X.to_numpy())\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X_columns_list = X.columns.to_list()\n",
    "\n",
    "        if self._fitted_columns is None:\n",
    "            raise ValueError(\"This instance should be fitted before calling predict\")\n",
    "        elif X_columns_list != self._fitted_columns:\n",
    "            raise ValueError(\n",
    "                f\"This model has been fitted on columns {self._fitted_columns}, but received {X_columns_list}\"\n",
    "            )\n",
    "\n",
    "        gamma = self.hmm.predict_proba(X.to_numpy())\n",
    "        persistence = 1 / (1 - np.diag(self.hmm.transmat_))\n",
    "\n",
    "        result = pd.DataFrame(\n",
    "            gamma,\n",
    "            columns=[f\"regime_gamma_{i}\" for i in range(gamma.shape[-1])],\n",
    "            index=X.index,\n",
    "        )\n",
    "        result[\"regime_persistence\"] = gamma @ persistence\n",
    "        return result\n",
    "\n",
    "\n",
    "class XGBoostQuantileRegressor:\n",
    "    def __init__(self, quantiles: List[float], **kwargs) -> None:\n",
    "        if \"objective\" in kwargs or \"quantile_alpha\" in kwargs:\n",
    "            raise ValueError(\n",
    "                \"Model kwargs may not contain the objective or quantile_alpha\"\n",
    "            )\n",
    "\n",
    "        self.quantile_models: Dict[str, xgb.XGBRegressor] = {\n",
    "            f\"p{q * 100:.0f}\": xgb.XGBRegressor(\n",
    "                objective=\"reg:quantileerror\", quantile_alpha=q, **kwargs\n",
    "            )\n",
    "            for q in quantiles\n",
    "        }\n",
    "        self._fitted_columns: Optional[List[str]] = None\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series) -> None:\n",
    "        self._fitted_columns = X.columns.to_list()\n",
    "\n",
    "        X_np = X.to_numpy()\n",
    "        y_np = y.to_numpy()\n",
    "\n",
    "        for _, model in self.quantile_models.items():\n",
    "            model.fit(X_np, y_np)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X_columns_list = X.columns.to_list()\n",
    "\n",
    "        if self._fitted_columns is None:\n",
    "            raise ValueError(\"This instance should be fitted before calling predict\")\n",
    "        elif X_columns_list != self._fitted_columns:\n",
    "            raise ValueError(\n",
    "                f\"This model has been fitted on columns {self._fitted_columns}, but received {X_columns_list}\"\n",
    "            )\n",
    "\n",
    "        X_np = X.to_numpy()\n",
    "\n",
    "        result = pd.DataFrame(\n",
    "            {\n",
    "                quantile_str: model.predict(X_np)\n",
    "                for quantile_str, model in self.quantile_models.items()\n",
    "            },\n",
    "            index=X.index,\n",
    "        )\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd6ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.filter(\n",
    "    pl.col(\"start_time_utc\") < pl.col(\"start_time_utc\").max() - dt.timedelta(weeks=1)\n",
    ").sort(\"start_time_utc\")\n",
    "X_test = X.filter(\n",
    "    pl.col(\"start_time_utc\") >= pl.col(\"start_time_utc\").max() - dt.timedelta(weeks=1)\n",
    ").sort(\"start_time_utc\")\n",
    "\n",
    "print(\n",
    "    f\"X_train range: [{X_train['start_time_utc'].min()}, {X_train['start_time_utc'].max()}]\"\n",
    ")\n",
    "print(\n",
    "    f\"X_test range: [{X_test['start_time_utc'].min()}, {X_test['start_time_utc'].max()}]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hmm = (\n",
    "    X_train.filter(\n",
    "        pl.col(\"start_time_utc\")\n",
    "        >= pl.col(\"start_time_utc\").max() - dt.timedelta(weeks=26)  # last 6 months\n",
    "    )\n",
    "    .select(\n",
    "        \"start_time_utc\",\n",
    "        \"abs_log_returns\",\n",
    "        \"log_range\",\n",
    "        \"realized_volatility\",\n",
    "        \"volsurp\",\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .set_index(\"start_time_utc\")\n",
    ")\n",
    "X_train_hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_model = RegimeSwitchingModel(\n",
    "    n_components=3,  # 3â€“4 regimes\n",
    "    covariance_type=\"full\",\n",
    "    n_iter=500,\n",
    "    tol=1e-4,\n",
    "    init_params=\"stmc\",  # startprob, transmat, means, covars\n",
    "    random_state=42,\n",
    ")\n",
    "hmm_model.fit(X_train_hmm)\n",
    "\n",
    "hmm_output_train = hmm_model.predict(\n",
    "    X_train.select(\n",
    "        \"start_time_utc\",\n",
    "        \"abs_log_returns\",\n",
    "        \"log_range\",\n",
    "        \"realized_volatility\",\n",
    "        \"volsurp\",\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .set_index(\"start_time_utc\")\n",
    ")\n",
    "hmm_output_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de63228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_xgb_polars = pl.concat(\n",
    "    [X_train, pl.from_pandas(hmm_output_train, include_index=True)], how=\"align_left\"\n",
    ").filter(\n",
    "    pl.col(\"start_time_utc\") >= pl.col(\"start_time_utc\").max() - dt.timedelta(days=365)\n",
    ")\n",
    "\n",
    "response_variable_name = \"log_returns_ahead_4\"\n",
    "features: List[str] = [\n",
    "    \"log_returns_4\",\n",
    "    \"volume\",\n",
    "    \"trading_day_sin\",\n",
    "    \"trading_day_cos\",\n",
    "    \"log_range\",\n",
    "    \"realized_volatility\",\n",
    "    \"volsurp\",\n",
    "    *[col for col in X_train_xgb_polars.columns if col.startswith(\"regime_\")],\n",
    "]\n",
    "\n",
    "X_train_xgb = (\n",
    "    X_train_xgb_polars.select(\n",
    "        \"start_time_utc\",\n",
    "        response_variable_name,\n",
    "        *features,\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .set_index(\"start_time_utc\")\n",
    ")\n",
    "\n",
    "\n",
    "y_train_xgb = X_train_xgb[response_variable_name]\n",
    "X_train_xgb = X_train_xgb.drop(response_variable_name, axis=1)\n",
    "\n",
    "X_train_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBoostQuantileRegressor(quantiles=[0.15, 0.5, 0.85], random_state=42)\n",
    "model.fit(X_train_xgb, y_train_xgb)\n",
    "\n",
    "y_train_predictions = model.predict(X_train_xgb)\n",
    "y_train_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc68e4a",
   "metadata": {},
   "source": [
    "### Forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HMM output\n",
    "X_test_hmm = (\n",
    "    X_test.select(\n",
    "        \"start_time_utc\",\n",
    "        \"abs_log_returns\",\n",
    "        \"log_range\",\n",
    "        \"realized_volatility\",\n",
    "        \"volsurp\",\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .set_index(\"start_time_utc\")\n",
    ")\n",
    "hmm_output_test = hmm_model.predict(X_test_hmm)\n",
    "\n",
    "# Create test dataset for ML model\n",
    "X_test_xgb_polars = pl.concat(\n",
    "    [X_test, pl.from_pandas(hmm_output_test, include_index=True)],\n",
    "    how=\"align_left\",\n",
    ")\n",
    "\n",
    "X_test_xgb = (\n",
    "    X_test_xgb_polars.select(\n",
    "        \"start_time_utc\",\n",
    "        *features,\n",
    "    )\n",
    "    .to_pandas()\n",
    "    .set_index(\"start_time_utc\")\n",
    ")\n",
    "\n",
    "\n",
    "# Create forecasts\n",
    "predictions = model.predict(X_test_xgb)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X_test[\"start_time_utc\"],\n",
    "        y=X_test[response_variable_name],\n",
    "        name=response_variable_name,\n",
    "    ),\n",
    ")\n",
    "\n",
    "for col in predictions.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=predictions.index,\n",
    "            y=predictions[col],\n",
    "            name=col,\n",
    "            line_color=f\"rgba(128, 0, 128, {'0.2' if col != 'p50' else '1'})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "lower_column = min(predictions.columns)\n",
    "upper_column = max(predictions.columns)\n",
    "\n",
    "# Upper bound\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=predictions.index,\n",
    "        y=predictions[upper_column],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=0),\n",
    "        name=\"Upper bound\",\n",
    "        showlegend=False,\n",
    "        hoverinfo=\"skip\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Lower bound (fills to previous trace)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=predictions.index,\n",
    "        y=predictions[lower_column],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=0),\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(128, 0, 128, 0.2)\",\n",
    "        name=\"Prediction interval\",\n",
    "        showlegend=False,\n",
    "        hoverinfo=\"skip\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    dict(\n",
    "        title=\"Log returns (t+k)\",\n",
    "        hovermode=\"x\",\n",
    "        xaxis=dict(\n",
    "            showline=True,\n",
    "            showspikes=True,\n",
    "            spikemode=\"across\",\n",
    "            spikesnap=\"cursor\",\n",
    "            spikedash=\"solid\",\n",
    "            spikecolor=\"black\",\n",
    "            spikethickness=1,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_close_prices = pl.concat(\n",
    "    [\n",
    "        X_test,\n",
    "        pl.from_pandas(predictions, include_index=True),\n",
    "    ],\n",
    "    how=\"align_full\",\n",
    ").with_columns(\n",
    "    *[\n",
    "        (pl.col(\"close\") * pl.col(col).exp()).shift(4).alias(f\"close_{col}\")\n",
    "        for col in predictions.columns\n",
    "    ]\n",
    ")\n",
    "predicted_close_prices = predicted_close_prices.select(\n",
    "    \"start_time_utc\",\n",
    "    *[col for col in predicted_close_prices.columns if col.startswith(\"close\")],\n",
    ")\n",
    "predicted_close_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=predicted_close_prices[\"start_time_utc\"],\n",
    "        y=predicted_close_prices[\"close\"],\n",
    "        name=\"close\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "columns_without_actuals = [\n",
    "    col\n",
    "    for col in predicted_close_prices.columns\n",
    "    if col not in (\"start_time_utc\", \"close\")\n",
    "]\n",
    "\n",
    "for col in columns_without_actuals:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=predicted_close_prices[\"start_time_utc\"],\n",
    "            y=predicted_close_prices[col],\n",
    "            name=col,\n",
    "            line_color=f\"rgba(128, 0, 128, {'1' if col.endswith('p50') else '0.2'})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "lower_column = min(columns_without_actuals)\n",
    "upper_column = max(columns_without_actuals)\n",
    "\n",
    "# Upper bound\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=predicted_close_prices[\"start_time_utc\"],\n",
    "        y=predicted_close_prices[upper_column],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=0),\n",
    "        name=\"Upper bound\",\n",
    "        showlegend=False,\n",
    "        hoverinfo=\"skip\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Lower bound (fills to previous trace)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=predicted_close_prices[\"start_time_utc\"],\n",
    "        y=predicted_close_prices[lower_column],\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=0),\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(128, 0, 128, 0.2)\",\n",
    "        name=\"Prediction interval\",\n",
    "        showlegend=False,\n",
    "        hoverinfo=\"skip\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    dict(\n",
    "        title=\"Close price vs predicted\",\n",
    "        hovermode=\"x\",\n",
    "        xaxis=dict(\n",
    "            showline=True,\n",
    "            showspikes=True,\n",
    "            spikemode=\"across\",\n",
    "            spikesnap=\"cursor\",\n",
    "            spikedash=\"solid\",\n",
    "            spikecolor=\"black\",\n",
    "            spikethickness=1,\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
